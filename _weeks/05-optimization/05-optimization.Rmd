---
title: "5 Optimization and model complexity"
description: |
  Machine learning is broadly about estimating functions using optimization algorithms. We can think of these as searching through a space of functions to find one that minimizes a measure of inaccuracy or loss.
author:
  - name: Joshua Loftus
date: 10-07-2021
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.retina = 3, warning = FALSE, message = FALSE)
library(tidyverse)
library(knitr)
library(gapminder)
theme_set(theme_minimal(base_size = 22))
```

## Materials

| Link | Type | Description             |
|:----:|:----:|:------------------------|
| [html](slides/05-1-optimization.html)  [pdf](slides/05-1-optimization_handout.pdf) | Slides | Optimization and model complexity
| [html](../04-classification/notebooks/gradient_descent.html) | Notebook | Gradient descent |
| [Rmd](notebooks/SGD.Rmd) | Notebook | Stochastic gradient descent |
| [Rmd](notebooks/leaps.Rmd) | Notebook | Stepwise variable selection |

*To be updated*

## Preparation

### Required reading

- [ISLR](https://www.statlearning.com/) Chapter 6, Section 1 only.
- [ISLR](https://www.statlearning.com/) Chapter 7, Sections 1-3 and 6.
- [MLstory](https://mlstory.org/) Chapter 5 on optimization, read the section on *Stochastic gradient descent* and stop after the *SGD quick start guide*.

### Supplemental reading

- [MLstory](https://mlstory.org/) Chapter 5 on optimization, the rest of the chapter (note that it contains some more advanced material).
- Wikipedia on [Newton's method](https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization) and [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) (good for pictures and animations)

## Optimization

## Overfitting

## Slides, notebooks, exercises

[Slides](slides/05-1-optimization.html) for optimization video ([PDF](slides/optimization.pdf))

[Slides](slides/05-2-overfitting.html) for overfitting video ([PDF](slides/overfitting.pdf))

[Notebook](notebooks/generalization.Rmd) for generalization ([partially complete](notebooks/generalization_incomplete.html))

[Notebook](notebooks/optimization.Rmd) for optimization ([partially complete](notebooks/optimization_incomplete.html))

[Notebook](notebooks/regularization.Rmd) for regularization ([partially complete](notebooks/regularization_incomplete.html))

[Exercises](exercises/cw2.Rmd) 
