---
title: "4 Classification"
description: |
  Categorical or qualitative outcome variables are ubiquitous. We review some supervised learning methods for classification, and see how these may be applied to observational causal inference.
author:
  - name: Joshua Loftus
date: 10-08-2021
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.retina = 3, warning = FALSE, message = FALSE)
library(tidyverse)
library(knitr)
library(gapminder)
theme_set(theme_minimal(base_size = 22))
```


## Materials

| Link | Type | Description             |
|:----:|:----:|:------------------------|
| [html](slides/04-1-classification.html)  [pdf](slides/04-1-classification_handout.pdf) | Slides | Classification and logistic regression
| [html] [Rmd](notebooks/classification.Rmd) | Notebook | Classification, class balance, ROC curves |
| [pdf](notebooks/gradient_descent.pdf) [html](notebooks/gradient_descent.html) [Rmd](notebooks/gradient_descent.Rmd) | Notebook | Gradient descent and numeric differentiation |
| [html](exercises/pset1.html) | Exercises | First exercise set |

**To be updated**

## Preparation

### Required reading


- [ISLR](https://www.statlearning.com/) Chapter 4. This chapter is a bit lengthy, so it's OK if you don't carefully follow all the mathematics in sections 4.4 and 4.5 as long as you understand the concepts.
- [MLstory](https://mlstory.org/) Start Chapter 5 on optimization, read the first two sections on Optimization Basics and on Gradient Descent. You can stop when you reach Proposition 3.

### Supplemental reading

- Wikipedia on [Newton's method](https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization) and [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) (good for pictures and animations)
- [CASI](https://hastie.su.domains/CASI/) Chapter 4 for MLE theory, Chapter 8 sections 8.1-8.3 (more advanced material)

## Carving nature at its joints

> "A good cook gets a new knife every year; he chops! Mediocre cooks change knives monthly; they hack. My knife now has 19 years on it; it’s carved several thousand oxen and the edge is as if I had just taken it from the sharpener. Those joints have gaps, and the knife’s edge no thickness, to put something infinitesimally thin in an empty space?! Effortless! It even allows the edge wander in with ample room to play. That is why, with 19 years on it, this knife’s edge is grindstone fresh." - Butcher Ding, [the Zhuangzi](https://plato.stanford.edu/entries/zhuangzi/#PonP)


