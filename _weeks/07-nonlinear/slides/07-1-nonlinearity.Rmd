---
title: "Machine learning"
subtitle: "Non-linear supervised learning"
author: "Joshua Loftus"
#institute: "LSE"
#date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: ["default", "xaringan-themer.css", "../../../theme.css"]
#    seal: false    
    lib_dir: libs
    nature:
      titleSlideClass: ["bottom", "left"]
      countdown: 59000
      highlightStyle: github
      highlightLines: true
      highlightSpans: true
      countIncrementalSlides: false
---

class: inverse

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(fig.retina = 3, warning = FALSE, message = FALSE)
options(knitr.table.format = "html")
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_duo_accent(
  primary_color = "#2d708e",
  secondary_color = "#230433",
  link_color = "#55c667",
  text_bold_color = '#f68f46',
  title_slide_background_color = "#ffffff", #"#042333",
  title_slide_background_image = "../../../files/theme/LSE/aerial2.jpg",
#    "https://upload.wikimedia.org/wikipedia/commons/1/1a/Workhouse_Nantwich.jpg",
  title_slide_background_size = "cover",
  ) #or contain
```

```{r xaringanextra, include=FALSE, warning=FALSE}
library(xaringanExtra)
#xaringanExtra::use_animate_all("slide_left")
xaringanExtra::use_tile_view()
xaringanExtra::use_panelset()
xaringanExtra::style_panelset_tabs(font_family = "inherit")
```

```{r tidyverse, include=FALSE, warning=FALSE}
library(tidyverse)
library(knitr)
theme_set(theme_minimal(base_size = 22))
set.seed(1)
library(broom)
library(modelr)
```

<style type="text/css">
.remark-slide-content {
    font-size: 1.2rem;
    padding: 1em 4em 1em 4em;
}
</style>

## Who's afraid of nonlinearity?

#### Simulated examples with pictures for intuition

#### What's different/difficult about nonlinear models

#### Concluding real data example

Upcoming lectures on variety of approaches

- Nearest neighbors
- Kernels
- Trees
- GAMs (Generalized Additive Models)
- Networks

Can use any for both **regression** and **classification**

---

# "Linear modeling **assumption**"

Why are we so often *assuming* linearity? (of the right hand side)

$$
g(\mathbb E[\mathbf y]) = \beta_0 + \beta^T \mathbf x
$$

- Easier to interpret, sure...
- But also easier to estimate

Sometimes non-linearity is clear from the data or domain info

Other times it's less clear, and makes it harder to learn a CEF


---

### Non-linear classification

Sometimes the relationships in the data are clearly nonlinear

.pull-left[
```{r circle-eg, echo = FALSE, fig.align='center', out.width="500px"}
n <- 800
circle <- data.frame(
  x1 = 1 - 2*runif(n),
  x2 = 1 - 2*runif(n)
) %>% 
  mutate(
    y = factor(rbinom(n, 1, 9/10 - 8*as.numeric(sqrt(x1^2 + x2^2) > .7)/10 ))
  )
circle_plot <-
  ggplot(circle, aes(x1, x2)) +
  geom_point(aes(shape = y, fill = y),
             color = "black", size = 2, stroke = 1,
             show.legend = FALSE, alpha =  .4) +
  scale_shape_manual(values=c(21, 22)) + 
  scale_fill_viridis_d(direction = 1, end = .8)
circle_plot
```
]
.pull-right[
```{r poly-eg, echo = FALSE, fig.align='center', out.width="500px"}
n <- 1600
circle <- data.frame(
  x1 = 1 - 2*runif(n),
  x2 = 1 - 2*runif(n)
) %>% 
  mutate(
    y = factor(rbinom(n, 1, 9/10 - 8*as.numeric(1 - x1/4 - x1^2 + 5*x1*x2 > .5)/10 ))
  )
circle_plot <-
  ggplot(circle, aes(x1, x2)) +
  geom_point(aes(shape = y, fill = y),
             color = "black", size = 2, stroke = 1,
             show.legend = FALSE, alpha =  .4) +
  scale_shape_manual(values=c(21, 22)) + 
  scale_fill_viridis_d(direction = 1, end = .8)
circle_plot
```
]

- Linear decision boundary $\to$ more/systematic errors
- Allow curving boundary $\to$ lower error rate, not systematic

---

### Non-linear regression

Other times it's less clear, based on noise level and sample size

.pull-left[
```{r nonlinear-reg-simple, echo = FALSE}
f <- function(x) -1 + 2*x - x^2
g <- function(x) sin(100*x)
gen_f <- function(x) {
  data.frame(x = x) %>%
  mutate(y = f(x) + rnorm(length(x)))
}
gen_fg <- function(D) {
  D %>%
    mutate(y = y + g(x))
}
set.seed(1)
n <- 400
x <- 2*runif(n) + .5
data_f <- gen_f(x)
plot_f <- ggplot(data_f, aes(x,y)) +
  geom_point(alpha = .5) +
  geom_smooth(se = FALSE, method = "lm", size = 2, linetype = "dashed") +
  theme(
  axis.text.x = element_blank(),
  axis.text.y = element_blank()) 
plot_f  +
  geom_line(aes(x,f(x)), color = "#00aa00", size = 1,
            data = data_grid(data_f, x = seq_range(x, 1000)))
```
]
.pull-right[
```{r  nonlinear-reg-sin, echo = FALSE}
data_fg <- gen_fg(data_f)
plot_fg <- ggplot(data_fg, aes(x,y)) +
  geom_point(alpha = .5) +
  geom_smooth(se = FALSE, method = "lm", size = 2, linetype = "dashed") +
  theme(
  axis.text.x = element_blank(),
  axis.text.y = element_blank())
plot_fg  +
  geom_line(aes(x,f(x)), color = "#00aa00", size = 1,
            data = data_grid(data_fg, x = seq_range(x, 1000)))
```

]

One CEF is $f(x) = -1 + 2x - x^2$, the other is $f(x) + g(x)$

---

### Fitting the "true" models

.pull-left[
```{r}
fit <- function(D) {
  list(
  lm(y ~ x, D),
  lm(y ~ f(x), D),
  lm(y ~ f(x) + g(x), D)) 
}
models_data_f <- 
  fit(data_f)
models_data_fg <- 
  fit(data_fg)
```
Lists of fitted models on each dataset
- Linear (underfit?)
- $f(x)$
- $f(x) + g(x)$
]
.pull-right[
```{r}
models_data_f
```
]

---

```{r highlight.output = c(6)}
map_dfr(models_data_f, glance) # true CEF = f
```

```{r highlight.output = c(6)}
map_dfr(models_data_fg, glance) # CEF = f + g
```

Both look like high noise level, but 1 has ~double $R^2$? `r emo::ji("face_with_raised_eyebrow")` 

---

### Revealing $f(x) + g(x)$ `r emo::ji("zany_face")` 

.pull-left[
```{r echo = FALSE}
plot_f +
  geom_line(aes(x,f(x)), color = "#00aa00", size = 1,
            data = data_grid(data_f, x = seq_range(x, 1000)))
```
]
.pull-right[
```{r echo = FALSE}
plot_fg +
  geom_line(aes(x,f(x) + g(x)), color = "#00aa00", size = 1,
            data = data_grid(data_fg, x = seq_range(x, 1000)))
```
]

Datasets *look* very similar, but $f+g$ fits one and not the other


---

## If not linear, then what?

Choose a **space of functions** to optimize over

- Linear functions in $p$ variables $\leftrightarrow$ vector space $\mathbb R^p$

- Polynomials up to a fixed, maximum degree: also finite dimensional vector space

- Many (non-linear) function spaces are **infinite dimensional** vector spaces

  - $\{ f_k(x) = \sin(k \pi x) : k \in \mathbb Z \}$ (Fourier basis)
  
  - Spaces of integrable functions, or differentiable

- Underlying math: linear algebra $\to$ functional analysis

---

### Intuitions about function spaces

- Optimize over a larger space $\to$ fit more complex models

- Bias-variance trade-off: *both* choice of right/good space of functions *and* amount of complexity in that space

  - e.g. periodic (like last example), right wavelengths
  
  - e.g. smooth, right amount of wiggliness
  
  - e.g. "Shape constraints" like monotonic, unimodal, (log-)concave (*Application*: epidemic trajectory)

Science/modeling/inference approach: domain knowledge, first principles

ML approach: whichever function space has current SOTA software (with easy to use default settings `r emo::ji("grinning_squinting_face")`)

---

### Optimizing over a large function space

```{r}
overfit <- function(D, k_range = 0:200) {
  fit_sin_k <- function(k) {
    fit_k <- lm(y ~ x + sin(k*x), data = D)
    glance(fit_k)$r.squared
  }
  r_squareds <- map_dbl(k_range, fit_sin_k)
  best_k <- k_range[which.max(r_squareds)]
  best_k
}
khat_f <- overfit(data_f)
khat_fg <- overfit(data_fg)
c(khat_f, khat_fg)
```

$$
\hat f(x) = \beta_0 + \beta_1 x + \beta_2 \sin(\hat k x)
$$

Apparently $\hat k = 1$ or $\hat k = 100$, respectively

---

### Plotting the "best" models

```{r echo = FALSE}
fhat_f <- function(x) sin(khat_f*x)
fhat_fg <- function(x) sin(khat_fg*x)
best_model_f <- lm(y ~ x + fhat_f(x), data = data_f)
best_model_fg <- lm(y ~ x + fhat_fg(x), data = data_fg)
```

.pull-left[
```{r echo = FALSE}
# signal_plot <- ggplot(data_f, aes(x,y)) +
#   geom_point(alpha = .5) +
#   geom_smooth(se = FALSE, method = "lm", linetype = "dashed", color = "#00aa00", size = 2) +
#   theme(
#   axis.text.x = element_blank(),
#   axis.text.y = element_blank())
# signal_
plot_f +
  #ggtitle("The 'best' (overfit) model") +
  geom_line(aes(x, .fitted), color = "blue", size = 1,
            data = augment(best_model_f,
                           newdata = data_grid(data_f,
                           x = seq_range(x, 1000))))
```
]
.pull-right[
```{r echo = FALSE}
plot_fg +
  #ggtitle("The 'best' (overfit) model") +
  geom_line(aes(x, .fitted), color = "blue", size = 1,
            data = augment(best_model_fg,
                           newdata = data_grid(data_fg,
                           x = seq_range(x, 1000))))
```
]

Can we believe this?

---

### So which is it?

When we aren't doing simulations we just have the data

.pull-left[
```{r echo = F}
plot_f + ggtitle("Test data could prevent overfitting")
```
]
.pull-right[
```{r echo = F}
plot_fg + ggtitle("Doomed to underfit?")
```
]

We don't know signal/noise level, function space, complexity...

---

### The "big data" advantange

With larger samples we could tell these two cases apart

.pull-left[
```{r echo = F}
set.seed(1)
n <- 10000
x <- 2*runif(n) + .5
bigdata_f <- gen_f(x)
bigdata_fg <- gen_fg(bigdata_f)
noise_plot <- ggplot(bigdata_f, aes(x,y)) +
  geom_point(alpha = .7) +
  geom_smooth(se = FALSE, method = "lm", size = 2, linetype = "dashed") +
  theme(
  axis.text.x = element_blank(),
  axis.text.y = element_blank())
noise_plot #+
    #geom_line(aes(x, .fitted), color = "blue", size = 2, data = augment(best_model_f, newdata = data_grid(bigdata_f, x = seq_range(x, 1000))))
```
]
.pull-right[
```{r echo = F}
signal_plot <- ggplot(bigdata_fg, aes(x,y)) +
  geom_point(alpha = .7) +
  geom_smooth(se = FALSE, method = "lm", linetype = "dashed", size = 2) +
  theme(
  axis.text.x = element_blank(),
  axis.text.y = element_blank())
signal_plot #+
  #geom_line(aes(x, .fitted), color = "blue", size = 2, data = augment(best_model_fg, newdata = data_grid(bigdata_fg, x = seq_range(x, 1000))))
```
]

Use more data for validation / in-distribution generalization

---

## Non-linearity and overfitting

Much of machine learning and "AI" is about having large enough datasets to search large spaces of functions and fit complex models without **variability problems** from overfitting

i.e. good in-distribution generalization (new data, same DGP)

#### Intuition: more complex models are more sensitive to small changes in the data, or more "brittle"

--

#### Statistical wisdom: another reason to prefer simpler models may be better out-of-distribution generalization

i.e. avoiding **bias problems** from overfitting

---

### Out-of-distribution generalization

What if we test on data outside the original range/distribution?

.pull-left[
```{r echo = F}
set.seed(1)
n <- 1000
x <- 5*runif(n) + .5
bigdata_f <- gen_f(x)
bigdata_fg <- gen_fg(bigdata_f)
noise_plot <- ggplot(bigdata_f, aes(x,y)) +
  geom_point(alpha = .7) +
  geom_smooth(se = FALSE, method = "lm", size = 2, linetype = "dashed") +
  theme(
  axis.text.x = element_blank(),
  axis.text.y = element_blank())
noise_plot +
    geom_line(aes(x, .fitted), color = "blue", size = 2,
            data = augment(best_model_f,
                           newdata = data_grid(bigdata_f,
                           x = seq_range(x, 1000))))
```
]
.pull-right[
```{r echo = F}
signal_plot <- ggplot(bigdata_fg, aes(x,y)) +
  geom_point(alpha = .7) +
  geom_smooth(se = FALSE, method = "lm", linetype = "dashed", size = 2) +
  theme(
  axis.text.x = element_blank(),
  axis.text.y = element_blank())
signal_plot +
  geom_line(aes(x, .fitted), color = "blue", size = 2,
            data = augment(best_model_fg,
                           newdata = data_grid(bigdata_fg,
                           x = seq_range(x, 1000))))
```
]

Simpler/"underfit" models (dashed lines) *might* do better

---

### Choosing function spaces and methods

Since this is a course in ML, we won't assume these choices can be informed by domain knowledge

A few examples based on high level **properties of the data** and **goals of the analysis** -- not an exhaustive list or flowchart

(Assuming data shape is rectangular and i.i.d., otherwise we need specialized models for other data/dependence types)

|    Goals   | $n > p$ (tall) | $n \approx p$ or $p > n$ (wide)    |
| :---        |    :----:   |          :---: |
| Prediction only      | Network methods       | Ridge   |
| + Interpretation   | See below        | Lasso      |

Additivity $\to$ GAMs. Interactions $\to$ tree methods

---

## Caveats 

- Nearest neighbors: more often treated as an uninteresting baseline for comparison

- Some methods can be combined, all can be customized, more "researcher degrees of freedom" -- and therefore more model complexity -- if there are more ways to customize (e.g. network models)

- Remember: "[All models are wrong](https://en.wikipedia.org/wiki/All_models_are_wrong) but some are useful"

- Remember: [No Free Lunch](https://en.wikipedia.org/wiki/No_free_lunch_in_search_and_optimization) -- methods that do well in one situation will do poorly in another

Learning about a diverse set of approaches helps our understanding, and you will have more than [one kind of tool](https://en.wiktionary.org/wiki/if_all_you_have_is_a_hammer,_everything_looks_like_a_nail) at your disposal

---

### Smooth non-linearity?

CEF based on bins (like nearest neighbors). Credit: Reddit user [SurfingPolice](https://www.reddit.com/r/dataisbeautiful/comments/lkjlhy/relationship_between_film_length_and_average_imdb/gnk46yh/)

```{r echo = FALSE, cache = TRUE}
titles <- read_tsv("~/Downloads/archive/title.basics.tsv")
ratings <- read_tsv("~/Downloads/archive/title.ratings.tsv")
df <- titles %>%
  filter(titleType  == "movie") %>%
  inner_join(ratings, by = "tconst") %>%
  mutate(runtimeMinutes = parse_number(runtimeMinutes, na = c("\\N")))
rm(titles)
rm(ratings)
```

```{r echo = FALSE, fig.height=6}
df %>%
  drop_na(runtimeMinutes) %>%
  filter(runtimeMinutes < 60 * 6, runtimeMinutes > 30, numVotes > 10) %>%
  mutate(roundedRuntimeMinutes = floor(runtimeMinutes),
         decade = startYear - startYear %% 10) %>%
  group_by(roundedRuntimeMinutes) %>%
  summarise(
    avgRatingPerTime = mean(averageRating),
    n_movies = n()
  ) %>%
  ggplot(aes(roundedRuntimeMinutes, avgRatingPerTime, color = n_movies)) +
  geom_point() +
  guides(color = FALSE) +
  labs(x = "Runtime", y = "Average Rating") +
  scale_x_continuous(breaks = seq(0, 360, 30)) +
  theme(axis.title = element_text(face = "bold"))
```

---
  
### Disaggregated (full data instead of bin averages)
  
```{r echo = FALSE}
df %>%
  drop_na(runtimeMinutes) %>%
  filter(runtimeMinutes < 60 * 6, runtimeMinutes > 30, numVotes > 10) %>%
  mutate(roundedRuntimeMinutes = floor(runtimeMinutes),
         decade = startYear - startYear %% 10) %>%
  filter(!is.na(decade), decade > 1930) %>%
  ggplot(aes(runtimeMinutes, averageRating)) +
  geom_point(alpha = 0.1) +
  guides(color = FALSE) +
  labs(x = "Runtime", y = "Average Rating")
```

