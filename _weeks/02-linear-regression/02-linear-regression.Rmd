---
title: "2 Linear regression"
description: |
  Reviewing linear regression and framing it as a prototypical example and source of intuition for other machine learning methods.
author:
  - name: Joshua Loftus
date: 10-10-2021
output:
  distill::distill_article:
    self_contained: false
preview: candy.png
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.retina = 3, warning = FALSE, message = FALSE)
library(tidyverse)
library(knitr)
library(gapminder)
theme_set(theme_minimal(base_size = 22))
```

## Materials

| Link | Type | Description             |
|:----:|:----:|:------------------------|
| [html](slides/02-1-regression_combined.html)  [pdf](slides/02-1-regression_handout.pdf) | Slides | Least-squares regression


## Preparation

### Required reading

- [ISLR](https://www.statlearning.com/) Chapter 3: Linear Regression.

This chapter is long but should be mostly a review of material from previous courses.

### Supplemental reading

- [ESL](https://hastie.su.domains/ElemStatLearn/) corresponding chapters
- [MLstory](https://mlstory.org) Fundamentals of prediction and Supervised learning chapters

### Computer setup

First, create a [GitHub](https://github.com/) using your LSE email address (or add your LSE email to your existing account if you have another one). You'll need this account later when we start uploading completed notebooks to a GitHub Classroom.

Second, identify a dataset that you can use to fit a multiple regression model (one outcome variable, multiple predictor variables). This way you can work on an example dataset that you're personally interested in. If you can't find something or have trouble loading it into R in time there are backup options in these packages:

- `fivethirtyeight` https://fivethirtyeight-r.netlify.app/
- `palmerpenguins` https://allisonhorst.github.io/palmerpenguins/
- `modeldata` https://modeldata.tidymodels.org/
- `nycflights13` https://nycflights13.tidyverse.org/

Just be sure to identify in advance which variable you'll use as an
outcome to predict, and which variables you might use as predictors


## Machine learning before the information age

## Multiple regression

Regression, when conditioning on more than one predictor variable.


