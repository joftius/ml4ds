---
title: "9 Less interpretable methods"
description: |
  Neural networks and ensemble methods like bagging, random forests, and boosting can greatly increase predictive accuracy at the cost of ease of interpretation.
author:
  - name: Joshua Loftus
date: 10-03-2021
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.retina = 3, warning = FALSE, message = FALSE)
library(tidyverse)
library(knitr)
library(gapminder)
theme_set(theme_minimal(base_size = 22))
```

## Trees and forests

## Compositional nonlinearity

## (not active yet) Slides, notebooks, exercises

[Slides](slides/09-1-ensembles.html) for (tree) ensembles ([PDF])

[Slides](slides/09-2-composition.html) for deep learning ([PDF])

[Notebook](notebooks/tree_splits.html) for tree splitting

