<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Machine learning</title>
    <meta charset="utf-8" />
    <meta name="author" content="Joshua Loftus" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/animate.css-xaringan/animate.slide_left.css" rel="stylesheet" />
    <link href="libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view/tile-view.js"></script>
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="../../../theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: right, top, title-slide

# Machine learning
## Causal inference
### Joshua Loftus

---


class: inverse









&lt;style type="text/css"&gt;
.remark-slide-content {
    font-size: 1.2rem;
    padding: 1em 4em 1em 4em;
}
&lt;/style&gt;

.pull-left[
![](chesterfield.jpg)
]
.pull-right[
![](lung-cancer-deaths.png)

Hey kids... don't smoke
]


---
class: inverse


[R. A. Fisher](https://www.newstatesman.com/international/science-tech/2020/07/ra-fisher-and-science-hatred) on [smoking](https://www.york.ac.uk/depts/maths/histstat/smoking.htm) and lung cancer (in 1957)

&gt; ... the B.B.C. gave me the opportunity of putting forward examples of the two classes of alternative theories which **any statistical association, observed without the predictions of a definite experiment**, allows--namely, (1) that the supposed effect **is really the cause**, or in this case that incipient cancer, or a pre-cancerous condition with chronic inflammation, is a factor in inducing the smoking of cigarettes, or (2) that cigarette smoking and lung cancer, though not mutually causative, are **both influenced by a common cause**, in this case the individual genotype ...

---

## Graphical notation for causality

&lt;img src="03-2-causality_files/figure-html/unnamed-chunk-1-1.png" width="504" style="display: block; margin: auto;" /&gt;

Variables: vertices (or nodes)

Relationships: directed edges (arrows) 

Shaded node / dashed edges: unobserved variable

---

Smoking causes cancer?

&lt;img src="03-2-causality_files/figure-html/unnamed-chunk-2-1.png" width="360" style="display: block; margin: auto;" /&gt;

Genotype is a common cause?

&lt;img src="03-2-causality_files/figure-html/unnamed-chunk-3-1.png" width="504" style="display: block; margin: auto;" /&gt;


---
class: inverse, middle, center

## Fisher: correlation is not causation

He did not use graphical notation like this

But the graphs can be very useful

---

## Explaining an observed correlation

We find a statistically significant correlation between `\(X\)` and `\(Y\)`

What does it mean?

1. False positive (spurious correlation)
2. `\(X\)` causes `\(Y\)`
3. `\(Y\)` causes `\(X\)`
4. Both have common cause `\(U\)` [possibly unobserved]

--

Statistically indistinguishable cases (without "experimental" data)

--

Importantly different consequences!

---

## A simple mathematical model of causality

Think about **interventions** that change some target variable `\(T\)`

- Forget about the arrows pointing into `\(T\)` (intervention makes them irrelevant)

--

- Change `\(T\)`, e.g. setting it to some arbitrary new value `\(T = t\)`

--

- This change propagates along directed paths out of `\(T\)` to all descendant variables of `\(T\)` in the graph, causing their values to change

--

All of these changes could be deterministic, but most likely in our usage they are probabilistic

---

.pull-left[
&lt;img src="03-2-causality_files/figure-html/unnamed-chunk-4-1.png" width="360" style="display: block; margin: auto;" /&gt;

&lt;img src="03-2-causality_files/figure-html/unnamed-chunk-5-1.png" width="360" style="display: block; margin: auto;" /&gt;


&lt;img src="03-2-causality_files/figure-html/unnamed-chunk-6-1.png" width="360" style="display: block; margin: auto;" /&gt;
]
.pull-right[

**Exercise**: in each of these cases, if we intervene on `\(X\)` which other variable(s) are changed as a result?


&lt;img src="03-2-causality_files/figure-html/unnamed-chunk-7-1.png" width="360" style="display: block; margin: auto;" /&gt;

]

---

### Computing counterfactuals

If we know/estimate *functions* represented by edges, we can simulate/compute the consequences of an intervention

`$$x = \text{exogeneous}, \quad  m = f(x) + \varepsilon_m, \quad y = g(m) + \varepsilon_y$$`

&lt;img src="03-2-causality_files/figure-html/unnamed-chunk-8-1.png" width="504" style="display: block; margin: auto;" /&gt;


--

`$$x \gets x',  \quad m \gets f(x') + \varepsilon_m, \quad y \gets g(f(x') + \varepsilon_m) + \varepsilon_y$$`
---

### Causal inference: much more difficult

*Predictive* machine learning is about

$$
p_{Y|X}(y|x)
$$
and regression--conditional expectation, conditional quantile, etc. If we passively observe some value of `\(x\)`, what would we observe about `\(y\)`?

--

*Causal inference* is about (various notations)

$$
p(y|\text{do}[X=x]), \quad \text{i.e.} \quad p_{}(y| X \gets x)
$$
i.e. what happens to `\(Y\)` when we actually **intervene** on `\(X\)`

If we actively change `\(x\)`, what would we observe about `\(y\)`?

---
class: inverse, center

### Experiments

Actually do interventions while collecting data

--

### Observational studies

Try to infer causal relationships without interventions, by using ~~dark arts~~ more/specialized assumptions/methods that require careful interpretation

--

Scientific progress: be wrong in more interesting/specific ways

---

### Potential outcomes: another causal framework

Relative strengths/weaknesses compared to DAGs

- Narrow focus: goal is to estimate one edge in a graph
- Difficult to express more complex relationships

--

### This is not a course on causal inference

Covering a few basics for interesting connections to ML!

#### So when is ML (and e.g. regression) useful for causal inference?

---

## Idea: adjusting for confounders

**Confounders**: other variables that obscure the (causal) relationship from `\(X\)` to `\(Y\)`, e.g.

- `\(Y\)`: health outcome
- `\(X\)`: treatment dose
- `\(Z\)`: disease severity

--

Without considering `\(Z\)`, it might seem like larger doses of `\(X\)` correlate with worse health outcomes

--

### Solution: add more variables to the model

Make model complex enough to capture important factors

Similarly, might need to model *non-linear causal relationships*

---

### Strategy: two staged regression

Two-stage least squares (2SLS)

Suppose we want to learn the causal relationship of `\(D\)` on `\(Y\)`, but

$$
Y = D \theta + X \beta + \varepsilon_Y
$$

$$
D = X \alpha + \varepsilon_D
$$
In words: `\(X\)` is confounding the relationship

--

- First stage: regress out `\(X\)`

- Second stage: using residuals from first stage,

`$$\text{regress } Y - X \hat \beta \text{ on } D - X \hat \alpha$$` 

---
class: inverse, center, middle

# Powerful, intuitive idea

## Orthogonal projection

### We'll come back to this

(Think about fitting the relationships using ML instead of regression)

---

## Propensity

General theme: applying ML strengths to causality

Special case: if the "treatment" (causal) variable is categorical

Many causal methods for this case involve predicting the treatment itself

i.e. prediction with categorical outcome, **classification**

We'll also come back to this ([propensity methods](https://en.wikipedia.org/wiki/Propensity_score_matching)) after covering classification

--

#### Summary: a key ingredient in many causal inference methods involves classification, can leverage ML tools

---
class: inverse

## Guiding ideas / warnings

- More complex models (ML) do not guarantee better causal inference

Might even make things worse (just like with prediction)

--

- Models with better predictions may be worse for causal inference

Even if prediction accuracy is measured on test data!

--

- Inference = causal inference...?

Or, at least, causal interpretations can be special case of trade-off between prediction and inference/interpretation

---
class: inverse, center, middle

# Causal inference

## An exciting interdisciplinary field

### Practically important, connections to ML

&gt; "Data scientists have hitherto only predicted the world in various ways; the point is to change it" - Joshua Loftus

Mixtape... remix? ðŸ¤”
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"highlightSpans": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
(function(time) {
  var d2 = function(number) {
    return ('0' + number).slice(-2); // left-pad 0 to minutes/seconds
  },

  time_format = function(total) {
    var secs = Math.abs(total) / 1000;
    var h = Math.floor(secs / 3600);
    var m = Math.floor(secs % 3600 / 60);
    var s = Math.round(secs % 60);
    var res = d2(m) + ':' + d2(s);
    if (h > 0) res = h + ':' + res;
    return res;  // [hh:]mm:ss
  },

  slide_number_div = function(i) {
    return document.getElementsByClassName('remark-slide-number').item(i);
  },

  current_page_number = function(i) {
    return slide_number_div(i).firstChild.textContent;  // text "i / N"
  };

  var timer = document.createElement('span'); timer.id = 'slide-time-left';
  var time_left = time, k = slideshow.getCurrentSlideIndex(),
      last_page_number = current_page_number(k);

  setInterval(function() {
    time_left = time_left - 1000;
    timer.innerHTML = ' ' + time_format(time_left);
    if (time_left < 0) timer.style.color = 'red';
  }, 1000);

  slide_number_div(k).appendChild(timer);

  slideshow.on('showSlide', function(slide) {
    var i = slide.getSlideIndex(), n = current_page_number(i);
    // reset timer when a new slide is shown and the page number is changed
    if (last_page_number !== n) {
      time_left = time; last_page_number = n;
      timer.innerHTML = ' ' + time_format(time); timer.style.color = null;
    }
    slide_number_div(i).appendChild(timer);
  });
})(59000);
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
