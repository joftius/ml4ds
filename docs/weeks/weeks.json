[
  {
    "path": "weeks/01-introduction-foundations/",
    "title": "1 Introduction and foundations",
    "description": "A brief introduction to the course, preview of things to come, and some foundational background material.",
    "author": [
      {
        "name": "Joshua Loftus",
        "url": {}
      }
    ],
    "date": "2021-10-11",
    "categories": [],
    "contents": "\nMaterials\nLink\nType\nDescription\nhtml pdf\nSlides\nCourse introduction\nhtml pdf\nSlides\nPreview of machine learning concepts\nhtml\nNotebook\ngapminder example\nhtml\nNotebook\ncandy example\nhtml\nNotebook\nPrevious (outdated) seminar\nUpdated notebooks will be available on GitHub.\nPreparation\nRequired reading\nISLR Chapter 1:\nIntroduction. Should be a quick read. Don’t skip the section on\nNotation and Simple Matrix Algebra.\nISLR Chapter 2:\nStatistical Learning.\nIf you finish these quickly you may want to start Chapter 3, because\nit’s a long one.\nSupplemental reading\nESL\ncorresponding chapters\nMLstory Introduction and\nMathematical background chapters\nInstalling R and\nRStudio\nFirst install R and then\ninstall RStudio\n(this second step is highly recommended but not required, if you prefer\nanother IDE and you’re sure you know what you’re doing). Finally, open\nRStudio and install the tidyverse set of packages\nby running the command\ninstall.packages(\"tidyverse\")\nNote: If you use a Mac or Linux-based computer you\nmay want to install these using a package manager instead of downloading\nthem from the websites linked above. Personally, on a Mac computer I use\nHomebrew (the link has instructions for\nhow to install it) to install\nR and RStudio.\nWhat is machine learning?\nWe begin with some key conceptual themes in machine learning. The\nsubject mainly focuses on algorithms for finding\npotentially useful structure in data.\nSupervised machine learning\nThis refers to the special case where one variable in the dataset is\nspecified as an “outcome”–usually represented as \\(y\\)–the other variables are considered\ninputs or “predictors”–written as \\(x\\)–and the algorithm attempts to “fit” a\nfunctional relationship between these using the dataset. A key idea in\napplied mathematics is that there may be some “true” function \\(f\\) that describes the relationship between\n\\(x\\) and \\(y\\), so that measured data will satisfy\n\\[\ny = f(x) + \\epsilon\n\\] where \\(\\epsilon\\) is a\n(hopefully small) “error” term. In the physical sciences, for example,\nthis function could describe a “law” such as the laws of mechanics or\nelecromagnetism, etc. In machine\nlearning we usually don’t know the function, or even have good a\npriori reasons to believe there is a useful functional\nrelationship. Instead we hope that a (powerful enough) algorithm can\n“learn” a function \\(\\hat f\\) by\napproximating the examples in a (large enough) dataset:\n\\[\n\\hat f(x_i) \\approx y_i, \\quad \\text{ for } \\quad i = 1, \\ldots, n\n\\] We might only care about the prediction accuracy of this\nlearned function, or we might also want to interpret it\nbased on the assumption that it is close to the “true” function: \\[\n\\hat f(x) \\approx f(x)\n\\] Technological advances in computing enable us to use more\nsophisticated algorithms and achieve better accuracy. This often creates\ntension between the two goals above, since new “state of the art”\n(SOTA) algorithms that have the highest prediction\naccuracy are usually very complicated and hence difficult to interpret.\nLater in the course we will learn about some algorithmic tools to help\nus interpret other algorithms.\nModel complexity\nThe distinguishing feature of machine learning as compared to\nstatistics, for example, is that it is mainly concerned with the\naccuracy of the fitted relationship. In statistics we usually want some\nkind of inference for our fitted models, for example\nconfidence/prediction intervals, hypothesis tests, and diagnostic plots.\nMachine learning drops this requirement allowing us to more kinds of\nmodels, including ones where we do not know how to compute valid\ninferences or provide any simple interpretations. To move in the\ndirection of machine learning, then, we can imagine starting at\nstatistics and taking a step in the direction of greater model\ncomplexity.\nTwo simple examples illustrate different strategies for building more\ncomplex models:\nincreasing complexity of the function class, for\nexample by using (more highly) non-linear functions and/or allowing\nfunctions to fit flexibly/locally to different subsets of the data\nincreasing the dimension of predictors (while\notherwise keeping the function class fixed)\nModel\ncomplexity relates to the bias-variance\ntrade-off: more complexity typically results in lower bias\nand higher variance.\n\n\n\nIncreasing complexity usually results in a lower mean-squared error\nif the MSE is calculated on the same dataset that was used to fit\nthe model. But if the MSE is calculated on a different dataset this\nis no longer true, and more complexity may result in a larger MSE on the\nother dataset.\nWhy should we evaluate model fit (like MSE) on a different dataset\nthan the one used to fit the model? First, if we evaluate it on the same\ndataset instead, then such an evaluation will always prefer greater\ncomplexity until the model “saturates” the data. In this case there was\nnothing gained from using a model–we have only created a map\nas large as the entire territory. Second, if our purpose in using a\nmodel is to describe some stable aspect of the world, if we\nthink the “true” \\(f\\) is something\nlike a “law of nature,” then we would hope that such a model would not\nimmediately fail if the time or context of the data collection is\nslightly different.\nSince these concepts are so central to machine learning we will\nreturn to them several times through the term and understand them\nthrough more examples and some mathematical derivations.\n\n\n\n",
    "preview": "https://ml4ds.com/weeks/01-introduction-foundations/slides/01-2-foundations_files/figure-html/gapminder-loess-1.png",
    "last_modified": "2022-10-05T15:42:06+01:00",
    "input_file": {}
  },
  {
    "path": "weeks/02-linear-regression/",
    "title": "2 Linear regression",
    "description": "Reviewing linear regression and framing it as a prototypical example and source of intuition for other machine learning methods.",
    "author": [
      {
        "name": "Joshua Loftus",
        "url": {}
      }
    ],
    "date": "2021-10-10",
    "categories": [],
    "contents": "\nMaterials\nLink\nType\nDescription\nhtml pdf\nSlides\nLeast-squares regression\nPreparation\nRequired reading\nISLR Chapter 3: Linear\nRegression.\nThis chapter is long but should be mostly a review of material from\nprevious courses.\nSupplemental reading\nESL\ncorresponding chapters\nMLstory Fundamentals of prediction\nand Supervised learning chapters\nComputer setup\nFirst, create a GitHub using your\nLSE email address (or add your LSE email to your existing account if you\nhave another one). You’ll need this account later when we start\nuploading completed notebooks to a GitHub Classroom.\nSecond, identify a dataset that you can use to fit a multiple\nregression model (one outcome variable, multiple predictor variables).\nThis way you can work on an example dataset that you’re personally\ninterested in. If you can’t find something or have trouble loading it\ninto R in time there are backup options in these packages:\nfivethirtyeight https://fivethirtyeight-r.netlify.app/\npalmerpenguins https://allisonhorst.github.io/palmerpenguins/\nmodeldata https://modeldata.tidymodels.org/\nnycflights13 https://nycflights13.tidyverse.org/\nJust be sure to identify in advance which variable you’ll use as an\noutcome to predict, and which variables you might use as predictors\nMachine learning\nbefore the information age\nMultiple regression\nRegression, when conditioning on more than one predictor\nvariable.\n\n\n\n",
    "preview": "weeks/02-linear-regression/candy.png",
    "last_modified": "2022-10-05T15:04:56+01:00",
    "input_file": {},
    "preview_width": 1226,
    "preview_height": 1002
  },
  {
    "path": "weeks/03-causality/",
    "title": "3 Multiple regression and causality",
    "description": "Multiple linear regression does not, by default, tell us anything about causality. But with the right data and careful interpretation we might be able to learn some causal relationships.",
    "author": [
      {
        "name": "Joshua Loftus",
        "url": {}
      }
    ],
    "date": "2021-10-09",
    "categories": [],
    "contents": "\nReadings\nMixtape\nSections 1.1, 1.2, and 3.1 up to 3.1.3 (stop before 3.1.4)\nRerum cognoscere causas\nVirgil:\n\nFortunate, who can know the causes of things\n\nSlides, notebooks, exercises\nSlides for first causality\nvideo (PDF)\nSlides for\nsecond causality video\nSlides\nfor logistic regression video\nNotebook from\nseminar\n\n\n\n",
    "preview": {},
    "last_modified": "2022-09-30T20:07:14+01:00",
    "input_file": {}
  },
  {
    "path": "weeks/04-classification/",
    "title": "4 Classification",
    "description": "Categorical or qualitative outcome variables are ubiquitous. We review some supervised learning methods for classification, and see how these may be applied to observational causal inference.",
    "author": [
      {
        "name": "Joshua Loftus",
        "url": {}
      }
    ],
    "date": "2021-10-08",
    "categories": [],
    "contents": "\nCarving nature at its joints\n\n“A good cook gets a new knife every year; he chops! Mediocre cooks change knives monthly; they hack. My knife now has 19 years on it; it’s carved several thousand oxen and the edge is as if I had just taken it from the sharpener. Those joints have gaps, and the knife’s edge no thickness, to put something infinitesimally thin in an empty space?! Effortless! It even allows the edge wander in with ample room to play. That is why, with 19 years on it, this knife’s edge is grindstone fresh.” - Butcher Ding, the Zhuangzi\n\nSlides, notebooks, exercises\nSlides for logistic regression lecture (PDF)\nSlides for SVM lecture (PDF)\nNotebook for seminar\n\n\n\n",
    "preview": {},
    "last_modified": "2022-09-18T15:01:05+01:00",
    "input_file": {}
  },
  {
    "path": "weeks/05-optimization/",
    "title": "5 Optimization and overfitting",
    "description": "Optimization is about finding the best model. With greater model complexity it becomes increasingly important to avoid overfitting: finding a model that is best for one specific dataset but does not generalize well to others.",
    "author": [
      {
        "name": "Joshua Loftus",
        "url": {}
      }
    ],
    "date": "2021-10-07",
    "categories": [],
    "contents": "\nOptimization\nOverfitting\nSlides, notebooks, exercises\nSlides for optimization video (PDF)\nSlides for overfitting video (PDF)\nNotebook for generalization (partially complete)\nNotebook for optimization (partially complete)\nNotebook for regularization (partially complete)\nExercises\n\n\n\n",
    "preview": {},
    "last_modified": "2022-09-18T15:01:05+01:00",
    "input_file": {}
  },
  {
    "path": "weeks/06-regularization/",
    "title": "6 Regularization and validation",
    "description": "When optimizing an ML model there are a variety of strategies to improve generalization from the training data. We can add a complexity penalty to the loss function, and we can evaluate the loss function on validation data.",
    "author": [
      {
        "name": "Joshua Loftus",
        "url": {}
      }
    ],
    "date": "2021-10-06",
    "categories": [],
    "contents": "\nRegularization\nValidation\nSlides, notebooks, exercises\nSlides for regularization video (PDF)\nSlides for lasso video (PDF)\nNotebook for validation\nNotebook for lasso\n\n\n\n",
    "preview": {},
    "last_modified": "2022-09-18T15:01:06+01:00",
    "input_file": {}
  },
  {
    "path": "weeks/07-nonlinear/",
    "title": "7 Nonlinear methods",
    "description": "Non-linearity may result in models that trade interpretability for increased predictive accuracy. These notes discuss the challenges of non-linearity and introduce nearest neighbors and kernel methods.",
    "author": [
      {
        "name": "Joshua Loftus",
        "url": {}
      }
    ],
    "date": "2021-10-05",
    "categories": [],
    "contents": "\nNearest neighbors\nKernel methods\nSlides, notebooks\nSlides for non-linearity video ([PDF])\nSlides for \\(k\\)-NN video ([PDF])\nSlides for kernel video ([PDF])\nNotebook for kernels\nNotebook for \\(k\\)-NN\n\n\n\n",
    "preview": {},
    "last_modified": "2022-09-18T15:01:06+01:00",
    "input_file": {}
  },
  {
    "path": "weeks/08-nonlinear/",
    "title": "8 More nonlinear methods",
    "description": "We continue our exploration of non-linear supervised machine learning approaches including tree based methods, GAMs, and neural networks and graphs structured learning.",
    "author": [
      {
        "name": "Joshua Loftus",
        "url": {}
      }
    ],
    "date": "2021-10-04",
    "categories": [],
    "contents": "\nTrees and forests\nGAMS\nCompositional nonlinearity\n(not active yet) Slides, notebooks, exercises\nSlides for GAMs video ([PDF])\nSlides for trees and forests video ([PDF])\nNotebook for ?\nExercises\n\n\n\n",
    "preview": {},
    "last_modified": "2022-09-18T15:01:06+01:00",
    "input_file": {}
  },
  {
    "path": "weeks/09-uninterpretable/",
    "title": "9 Less interpretable methods",
    "description": "Neural networks and ensemble methods like bagging, random forests, and boosting can greatly increase predictive accuracy at the cost of ease of interpretation.",
    "author": [
      {
        "name": "Joshua Loftus",
        "url": {}
      }
    ],
    "date": "2021-10-03",
    "categories": [],
    "contents": "\nTrees and forests\nCompositional nonlinearity\n(not active yet) Slides, notebooks, exercises\nSlides for (tree) ensembles ([PDF])\nSlides for deep learning ([PDF])\nNotebook for tree splitting\n\n\n\n",
    "preview": {},
    "last_modified": "2022-09-18T15:01:06+01:00",
    "input_file": {}
  },
  {
    "path": "weeks/10-action/",
    "title": "10 From prediction to action",
    "description": "Supervised machine learning methods excel at predicting an outcome. But being able to predict an outcome does not mean we know how to change it, or that we should.",
    "author": [
      {
        "name": "Joshua Loftus",
        "url": {}
      }
    ],
    "date": "2021-10-02",
    "categories": [],
    "contents": "\nInterpretation\nWhy did the model predict this outcome?\nWhy did this outcome occur?\nProfessional ethics\nWhy are we doing any of this?\n(not active yet) Slides, notebooks, exercises\nSlides for interpretation ([PDF])\nSlides for ethics ([PDF])\nNotebook for interpretation methods\n\n\n\n",
    "preview": {},
    "last_modified": "2022-09-18T15:01:07+01:00",
    "input_file": {}
  }
]
